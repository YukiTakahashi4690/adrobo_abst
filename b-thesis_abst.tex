\documentclass[10pt]{ujarticle}
\usepackage{float}
\usepackage{adrobo_abst}
\usepackage{graphicx}
\usepackage[dvipdfmx]{color}
\usepackage{amssymb,amsmath}
\usepackage{bm}
\usepackage[superscript]{cite}
\usepackage{enumerate}
\usepackage{url}
% \usepackage{caption}
% \captionsetup[table]{format=plain, labelsep=colon, font={up, normalsize}}
% \usepackage[dvipdfmx]{color}
%\usepackage[absolute]{textpos}

\renewcommand\citeform[1]{(#1)}

\begin{document}
    
    \makeatletter
    \doctype{2022年度卒業論文概要}
    \title{視覚と行動のend-to-end学習により\\経路追従行動をオンラインで模倣する手法の提案}{(オフラインでデータセットを収集して訓練する手法の提案)}
    \etitle{A proposal for an online imitation method of path-tracking behavior by end-to-end learning of vision and action}{(Validation of a method to collect and train dataset offline)}
    
    \author{19C1068\hspace{.5zw}髙橋祐樹}
    \eauthor{Yuuki TAKAHASHI}
    
    \makeatother
    
    \abstract{In this paper, we propose a method of training a robot by collecting data on and near a target path, based on a conventional method of imitation path-following behavior. In the proposed method, the robot is placed on and around the target path and data is collected. Then, the robot is trained off-line using the collected data. After learning, the robot runs according to the output of the trainer using camera images as input. This is performed on a simulator, and the effectiveness of the proposed method is verified through experiments. As a result, it is confirmed that the proposed method can run around the path.}
    
    \keywords{End-to-End Learning, Navigation, Offline}
    
    \maketitle
    
    \supervisor{指導教員：林原靖男 教授}
    
    \section{緒\hspace{2zw}言}%===========================
    近年, 自律移動ロボットの研究が盛んに行われている. Bojarskiら\cite{bojarski}は人が操作するステアリングの角度をend-to-end学習することで, 自律走行する手法を提案した. また, 岡田ら\cite{si2020-okada}は, 地図を用いたルールベース制御器の出力を模倣することで経路追従行動を獲得した(以下｢従来手法｣と称する). しかし, 学習器の出力で自律走行させるには, ロボットを何周を走行させる必要があり, 時間や手間が必要となる. 本研究では, 従来手法を基に目標経路上及び周辺のデータを一度に収集してオフラインで訓練する手法を提案する. さらに訓練後に, カメラ画像を入力とした学習器の出力で自律走行させることで手法の有効性を検証することを目的とする. 
    % しかし, カメラ画像を入力とした学習器の出力で自律走行をするには, ロボットを何周も走行させて学習する必要があり, 手間や時間が掛かる.
    % また, 清岡ら\cite{si2021-kiyooka}により, 経路上だけでなく経路から離れた状態も学習することが, 経路追従行動を模倣する上で有効であることも示されている.
    
    \section{従来手法}%===========================
    従来手法に関して述べる. 従来手法では, 地図を用いたルールベース制御器の出力を模倣し, 経路追従行動を獲得する. 図\ref{Fig:si2020-okada}に示すシステムでは, LiDAR, オドメトリを入力としたnavigation\cite{navigation}の出力である角速度(以下｢目標角速度｣と称する)を学習器とモータ駆動系に与える. また, 学習器には, カメラ画像を64×48にリサイズした3つのカメラ画像を入力し,目標角速度を出力してend-to-end学習する. 左右のカメラ画像に対する角速度には, それぞれ経路に戻るようなオフセットを加える. 学習後は, カメラ画像を入力とした学習器の出力により走行する. 

    \begin{figure}[h]
        \centering
        \includegraphics[keepaspectratio, scale=0.3]{fig/si2020-okada.png}
        \caption{Systems that imitation learning for map-based navigation from\cite{si2020-okada}}
        \label{Fig:si2020-okada}
    \end{figure}

    \section{提案手法}%===========================
    本研究で提案する手法を述べる. 従来手法に対して, 提案手法は一度にデータを収集して, オフラインで訓練することが異なる. 図\ref{Fig:collect}にデータの収集方法を示す. 赤線の目標経路から平行に離れた座標にロボットを配置して, カメラ画像と目標角速度を収集する. その後, 収集したデータを用いてオフラインで学習を行う. 

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.35\textwidth]{fig/collect-data2.png}
        \caption{Method of collecting data around the target route}
        \label{Fig:collect}
    \end{figure}

    \section{シミュレータを用いた実験}%=========================== 
    \subsection{実験装置}シミュレータにはGazeboのWillow Garage\cite{willow}を用いて, 図\ref{Fig:willow}に示すコースで一周行う. また, ロボットモデルにはカメラを3つ搭載したTurtlebo3 Waffle Piを用いた. 

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.3\textwidth]{fig/willow-path.png}
        \caption{Course to collect data}
        \label{Fig:willow}
    \end{figure}

    \subsection{実験方法}
    \begin{description}
        \item[1.データ収集フェーズ]図\ref{Fig:collect-data}にデータの収集方法を示す. 赤線の目標経路から平行に±0.01, ±0.02, ±0.04, ±0.06, ±0.08, ±0.10, ±0.15, ±0.20, ±0.30[m]離れた座標にロボットを配置する. そして, その座標ごとに経路に沿った向きを基準として±5度傾けて, カメラ画像と目標角速度を収集する. 
        \item[2.訓練フェーズ]4000step, 2000step学習した. なお, 4000stepは従来研究において, シミュレータの実験に用いられてきたステップ数である. 
        \item[3.テストフェーズ]図\ref{Fig:willow}に示したコースで10個の学習済みモデルを用いて走行させる. 経路を3周できた場合を成功とし, 壁に衝突したり, 目標経路から10[m]以上離れたりした場合を失敗とした. 
    \end{description}

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.45\textwidth]{fig/collect-data.png}
        \caption{Method of collecting data around the target route}
        \label{Fig:collect-data}
    \end{figure}

    \subsection{実験結果}実験結果を表\ref{tb:result}に示す. 4000stepは成功率100\%, 6分20秒で学習が終了した. 2000stepは成功率80\%であるが, 学習は3分10秒で終了した. ここで, 学習時のlossを図\ref{Fig:loss}に示す. 図\ref{Fig:loss}から学習が収束していることが確認できる. また, 従来手法が訓練に最低40分程度必要であったのに対して, 大幅に時間を短縮できることを確認した. 

    \begin{table}[h]
        \caption{Number of successes in the experiment}
        \centering
        \scalebox{0.8}{
        \begin{tabular}{|c|c|} \hline
          Experiments & Number of successes \\ \hline
          Exp.1(4000step) & 10/10 \\ \hline
          Exp.2(2000step) & 8/10 \\ \hline
        \end{tabular}
        }
        \label{tb:result}
      \end{table}

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.4\textwidth]{fig/loss_compe.png}
        \caption{Loss value in the experiments}
        \label{Fig:loss}
    \end{figure}

    \section{結\hspace{2zw}言}%===========================
    本稿では, 従来研究を基にオフラインでデータセットを収集して訓練する手法を提案した. そして, 実験により提案手法の有効性を確認した. 

    \vspace{5truemm}
    {\footnotesize
        \begin{thebibliography}{99}

            \bibitem{bojarski}
            Bojarsi, Mariusz, et al.:``End to End Learning for Self-Driving Cars.'', arXiv: 1604.07316, 2016
            
            \bibitem{si2020-okada}
            岡田 眞也, 清岡 優祐, 上田 隆一, 林原 靖男: ``視覚と行動のend-to-end学習により経路追従行動をオンラインで模倣する手法の提案'', \textit{計測自動制御学会 SI 部門講演会 SICE-SI2021 予稿集}, pp.1147-1152, 2020.

            % \bibitem{si2021-okada}
            % 岡田 眞也, 清岡 優祐, 春山 健太, 上田 隆一, 林原 靖男: ``視覚と行動のend-to-end学習により経路追従行動をオンラインで模倣する手法の提案-“経路追従行動の修正のためにデータセットを動的に追加する手法の検討'', \textit{計測自動制御学会 SI 部門講演会 SICE-SI2021 予稿集}, pp.1066-1070, 2021.

            % \bibitem{si2021-kiyooka}
            % 清岡 優祐, 岡田 眞也, 岩井 一輝, 上田 隆一, 林原 靖男: ``視覚と行動のend-to-end学習により経路追従行動をオンラインで模倣する手法の提案''-データセットと生成された経路追従行動の解析'', \textit{計測自動制御学会 SI 部門講演会 SICE-SI2021 予稿集}, pp.1072-1075, 2021.

            \bibitem{navigation}
            ros-planning, navigation リポジトリ\\
            \url{https://github.com/ros-planning/navigation}\\
            (最終閲覧日 \today)

            % \bibitem{gazebo}
            % gazebo リポジトリ\\
            % \url{http://gazebosim.org/}\\
            % (最終閲覧日 \today)

            \bibitem{willow}
            Koenig, Nathan, and Andrew Howard. ”design and use paradigms for gazebo, an open-source multi-robot simulator.”. 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)(IEEE Cat. No. 04CH37566). Vol. 3. IEEE, pp.2149-2154(2004).\\
            (最終閲覧日 \today)

            % \bibitem{turtlebot3}
            % Turtlebot3-robotis emanual.robotis.\\
            % \url{https://emanual.robotis.com/docs/.}\\
            % (最終閲覧日 \today)
            
        \end{thebibliography}
    }
\end{document}
